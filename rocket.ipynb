{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROCKET model in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_rocket(df, pad_length=250):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    # Get the sequence for each vehicle\n",
    "    for vehicle_id in df[\"vehicle_id\"].unique():\n",
    "        vehicle_data = df[df[\"vehicle_id\"] == vehicle_id]\n",
    "        vehicle_data = vehicle_data.sort_values(by=\"time_step\")\n",
    "        \n",
    "        # Extract the features (excluding vehicle_id, time_step, class)\n",
    "        feature_columns = [col for col in df.columns if col not in [\"vehicle_id\", \"time_step\", \"class\"]]\n",
    "        features = vehicle_data[feature_columns].values\n",
    "        \n",
    "        # Extract the class for each sequence\n",
    "        class_label = vehicle_data[\"class\"].iloc[-1]\n",
    "        \n",
    "        #print(features.shape)\n",
    "        #print(len(features))\n",
    "        if len(features) < pad_length:\n",
    "            # Pad the feature sequence with 0\n",
    "            padded_features = np.pad(features, ((0, pad_length - len(features)), (0, 0)), constant_values=0)\n",
    "        else:\n",
    "            # Truncate if sequence to long\n",
    "            padded_features = features[:pad_length]\n",
    "        \n",
    "        X_data.append(padded_features)\n",
    "        y_data.append(class_label)\n",
    "    \n",
    "    X_data = np.array(X_data)  # (num_samples, pad_length, num_features)\n",
    "    y_data = np.array(y_data)  # (num_samples,)\n",
    "    \n",
    "    return X_data, y_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1_train = pd.read_csv(\"datasets/train_dataset_1.csv\")\n",
    "X_train_1, y_train_1 = prep_data_for_rocket(dataset_1_train)\n",
    "\n",
    "dataset_2_train = pd.read_csv(\"datasets/train_dataset_1.csv\")\n",
    "X_train_2, y_train_2 = prep_data_for_rocket(dataset_2_train)\n",
    "\n",
    "print(\"Dataset 1\")\n",
    "print(\"X: \", X_train_1.shape)\n",
    "print(\"y: \", y_train_1.shape)\n",
    "\n",
    "print(\"Dataset 2\")\n",
    "print(\"X: \", X_train_2.shape)\n",
    "print(\"y: \", y_train_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1_val = pd.read_csv(\"datasets/val_dataset_1.csv\")\n",
    "X_val_1, y_val_1 = prep_data_for_rocket(dataset_1_val)\n",
    "\n",
    "dataset_2_val = pd.read_csv(\"datasets/val_dataset_2.csv\")\n",
    "X_val_2, y_val_2 = prep_data_for_rocket(dataset_2_val)\n",
    "\n",
    "print(\"Dataset 1\")\n",
    "print(\"X: \", X_val_1.shape)\n",
    "print(\"y: \", y_val_1.shape)\n",
    "\n",
    "print(\"Dataset 2\")\n",
    "print(\"X: \", X_val_2.shape)\n",
    "print(\"y: \", y_val_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1_test = pd.read_csv(\"datasets/test_dataset_1.csv\")\n",
    "X_test_1, y_test_1 = prep_data_for_rocket(dataset_1_test)\n",
    "\n",
    "dataset_2_test = pd.read_csv(\"datasets/test_dataset_2.csv\")\n",
    "X_test_2, y_test_2 = prep_data_for_rocket(dataset_2_test)\n",
    "\n",
    "print(\"Dataset 1\")\n",
    "print(\"X: \", X_test_1.shape)\n",
    "print(\"y: \", y_test_1.shape)\n",
    "\n",
    "print(\"Dataset 2\")\n",
    "print(\"X: \", X_test_2.shape)\n",
    "print(\"y: \", y_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the features with the ROCKET model for two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket_1 = Rocket(num_kernels=10_000, random_state=50)\n",
    "rocket_1.fit(X_train_1)\n",
    "X_train_transformed_1 = rocket_1.transform(X_train_1)\n",
    "X_val_transformed_1 = rocket_1.transform(X_val_1)\n",
    "X_test_transformed_1 = rocket_1.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket_2 = Rocket(num_kernels=10_000, random_state=50)\n",
    "rocket_2.fit(X_train_2)\n",
    "X_train_transformed_2 = rocket_2.transform(X_train_2)\n",
    "X_val_transformed_2 = rocket_2.transform(X_val_2)\n",
    "X_test_transformed_2 = rocket_2.transform(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_transformed_1.shape)\n",
    "print(X_val_transformed_1.shape)\n",
    "print(X_test_transformed_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_transformed_2.shape)\n",
    "print(X_val_transformed_2.shape)\n",
    "print(X_test_transformed_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the classifier on the transformed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_logisctic_regression(X_train, y_train, X_val, y_val, c_values):\n",
    "    results = {\"c_values\": [], \n",
    "                \"train_accuracy\": [], \n",
    "                \"val_accuracy\": [], \n",
    "                \"train_loss\": [], \n",
    "                \"val_loss\": [],\n",
    "                \"models\": []\n",
    "                }\n",
    "\n",
    "    for c in c_values:\n",
    "        # Initialize and train the model\n",
    "        model = LogisticRegression(C=c, solver=\"newton-cg\", max_iter=1000, random_state=50)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Probabilities for log loss\n",
    "        y_train_proba = model.predict_proba(X_train)\n",
    "        y_val_proba = model.predict_proba(X_val)\n",
    "\n",
    "        # Calculate accuracy and log loss\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        val_acc = accuracy_score(y_val, y_val_pred)\n",
    "        train_loss = log_loss(y_train, y_train_proba)\n",
    "        val_loss = log_loss(y_val, y_val_proba)\n",
    "\n",
    "        # Store results\n",
    "        results[\"c_values\"].append(c)\n",
    "        results[\"train_accuracy\"].append(train_acc)\n",
    "        results[\"val_accuracy\"].append(val_acc)\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"models\"].append(model)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_VALUES = [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01]\n",
    "model_1 = train_and_evaluate_logisctic_regression(X_train_transformed_1,\n",
    "                                                  y_train_1,\n",
    "                                                  X_val_transformed_1,\n",
    "                                                  y_val_1,\n",
    "                                                  C_VALUES)\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = train_and_evaluate_logisctic_regression(X_train_transformed_2,\n",
    "                                                  y_train_2,\n",
    "                                                  X_val_transformed_2,\n",
    "                                                  y_val_2,\n",
    "                                                  C_VALUES)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set(model, X, y_true):\n",
    "\n",
    "    # Make predictions\n",
    "    y_test_pred = model.predict(X)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_true, y_test_pred)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test_2, y_test_pred)\n",
    "\n",
    "    # Print Metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Detailed Classification Report\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test_2, y_test_pred))\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_1 = model_1[\"models\"][2]\n",
    "print(final_model_1)\n",
    "eval_on_test_set(final_model_1, X_test_transformed_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_2 = model_2[\"models\"][2] # c=1e-05\n",
    "print(final_model_2)\n",
    "eval_on_test_set(final_model_2, X_test_transformed_2, y_test_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
